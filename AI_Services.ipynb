{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Rekognition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon Rekognition makes it easy to add image and video analysis to your applications. You just provide\n",
    "an image or video to the Amazon Rekognition API, and the service can identify objects, people, text,\n",
    "scenes, and activities. It can detect any inappropriate content as well. Amazon Rekognition also provides\n",
    "highly accurate facial analysis, face comparison, and face search capabilities. You can detect, analyze, and\n",
    "compare faces for a wide variety of use cases, including user verification, cataloging, people counting,\n",
    "and public safety\n",
    "\n",
    "For more details:  https://docs.aws.amazon.com/rekognition/latest/dg/rekognition-dg.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Amazon Rekognition Works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon Rekognition provides two API sets. You use Amazon Rekognition Image for:\n",
    "- Analyzing images\n",
    "- Analyzing videos\n",
    "\n",
    "Both APIs analyze images and videos to provide insights you can use in your applications. For example,\n",
    "you could use Amazon Rekognition Image to enhance the customer experience for a photo management\n",
    "application. When a customer uploads a photo, your application can use Amazon Rekognition Image to\n",
    "detect real-world objects or faces in the image. After your application stores the information returned\n",
    "from Amazon Rekognition Image, the user could then query their photo collection for photos with a\n",
    "specific object or face. Deeper querying is possible. \n",
    "\n",
    "**Amazon Rekognition image** operations are **`synchronous`**. The input and response are in JSON format. The\n",
    "image passed to an Amazon Rekognition Image operation can be stored in an Amazon S3 bucket. If\n",
    "you are not using the AWS CLI, you can also pass Base64 encoded images bytes directly to an Amazon\n",
    "Rekognition operation.\n",
    "\n",
    "**Amazon Rekognition Video** can analyze videos stored in an Amazon S3 bucket and videos streamed through Amazon Kinesis Video Streams. Amazon Rekognition Video video operations are **`asynchronous`**. With Amazon Rekognition Video storage video operations, you start analysis by calling the start operation for the type of analysis you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets use Python to play with the API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first import the **`boto3`** module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the S3 Bucket and Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your S3 Bucket and Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET ='my-ai-bucket-suman'     # Your S3 bucket name\n",
    "KEY ='photo3.jpeg'               # Your key/file/image/etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creatining a Rekognition Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "rekognition = boto3.client('rekognition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "rekognition_methods = [ m for m in dir(rekognition) if not m.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['can_paginate',\n",
       " 'compare_faces',\n",
       " 'create_collection',\n",
       " 'create_project',\n",
       " 'create_project_version',\n",
       " 'create_stream_processor',\n",
       " 'delete_collection',\n",
       " 'delete_faces',\n",
       " 'delete_stream_processor',\n",
       " 'describe_collection',\n",
       " 'describe_project_versions',\n",
       " 'describe_projects',\n",
       " 'describe_stream_processor',\n",
       " 'detect_custom_labels',\n",
       " 'detect_faces',\n",
       " 'detect_labels',\n",
       " 'detect_moderation_labels',\n",
       " 'detect_text',\n",
       " 'exceptions',\n",
       " 'generate_presigned_url',\n",
       " 'get_celebrity_info',\n",
       " 'get_celebrity_recognition',\n",
       " 'get_content_moderation',\n",
       " 'get_face_detection',\n",
       " 'get_face_search',\n",
       " 'get_label_detection',\n",
       " 'get_paginator',\n",
       " 'get_person_tracking',\n",
       " 'get_text_detection',\n",
       " 'get_waiter',\n",
       " 'index_faces',\n",
       " 'list_collections',\n",
       " 'list_faces',\n",
       " 'list_stream_processors',\n",
       " 'meta',\n",
       " 'recognize_celebrities',\n",
       " 'search_faces',\n",
       " 'search_faces_by_image',\n",
       " 'start_celebrity_recognition',\n",
       " 'start_content_moderation',\n",
       " 'start_face_detection',\n",
       " 'start_face_search',\n",
       " 'start_label_detection',\n",
       " 'start_person_tracking',\n",
       " 'start_project_version',\n",
       " 'start_stream_processor',\n",
       " 'start_text_detection',\n",
       " 'stop_project_version',\n",
       " 'stop_stream_processor',\n",
       " 'waiter_names']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rekognition_methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_labels(bucket, key, max_labels=10, min_confidence=90):\n",
    "    rekognition = boto3.client(\"rekognition\")\n",
    "    \n",
    "    response = rekognition.detect_labels(\n",
    "        Image={\n",
    "            'S3Object': {\n",
    "                'Bucket': bucket,\n",
    "                'Name': key\n",
    "            }\n",
    "        },\n",
    "        MaxLabels = max_labels,\n",
    "        MinConfidence = min_confidence\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return response[\"Labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Name': 'Person',\n",
       "  'Confidence': 99.82290649414062,\n",
       "  'Instances': [{'BoundingBox': {'Width': 0.26535969972610474,\n",
       "     'Height': 0.860253095626831,\n",
       "     'Left': 0.0006005956092849374,\n",
       "     'Top': 0.12097695469856262},\n",
       "    'Confidence': 99.37284088134766},\n",
       "   {'BoundingBox': {'Width': 0.3107784390449524,\n",
       "     'Height': 0.8664252161979675,\n",
       "     'Left': 0.6849671602249146,\n",
       "     'Top': 0.12964887917041779},\n",
       "    'Confidence': 99.36697387695312},\n",
       "   {'BoundingBox': {'Width': 0.390875905752182,\n",
       "     'Height': 0.9496490359306335,\n",
       "     'Left': 0.28974413871765137,\n",
       "     'Top': 0.04552329704165459},\n",
       "    'Confidence': 98.57737731933594},\n",
       "   {'BoundingBox': {'Width': 0.2159295231103897,\n",
       "     'Height': 0.8552320003509521,\n",
       "     'Left': 0.5649817585945129,\n",
       "     'Top': 0.09204504638910294},\n",
       "    'Confidence': 98.13015747070312},\n",
       "   {'BoundingBox': {'Width': 0.22536101937294006,\n",
       "     'Height': 0.9193332195281982,\n",
       "     'Left': 0.2171613872051239,\n",
       "     'Top': 0.05209572985768318},\n",
       "    'Confidence': 96.75590515136719}],\n",
       "  'Parents': []},\n",
       " {'Name': 'Face',\n",
       "  'Confidence': 99.82290649414062,\n",
       "  'Instances': [],\n",
       "  'Parents': [{'Name': 'Person'}]},\n",
       " {'Name': 'Human',\n",
       "  'Confidence': 99.82290649414062,\n",
       "  'Instances': [],\n",
       "  'Parents': []},\n",
       " {'Name': 'People',\n",
       "  'Confidence': 97.90164947509766,\n",
       "  'Instances': [],\n",
       "  'Parents': [{'Name': 'Person'}]},\n",
       " {'Name': 'Female',\n",
       "  'Confidence': 93.74052429199219,\n",
       "  'Instances': [],\n",
       "  'Parents': [{'Name': 'Person'}]},\n",
       " {'Name': 'Family',\n",
       "  'Confidence': 93.50811767578125,\n",
       "  'Instances': [],\n",
       "  'Parents': [{'Name': 'People'}, {'Name': 'Person'}]},\n",
       " {'Name': 'Photography',\n",
       "  'Confidence': 90.22195434570312,\n",
       "  'Instances': [],\n",
       "  'Parents': [{'Name': 'Person'}]},\n",
       " {'Name': 'Photo',\n",
       "  'Confidence': 90.22195434570312,\n",
       "  'Instances': [],\n",
       "  'Parents': [{'Name': 'Person'}]},\n",
       " {'Name': 'Portrait',\n",
       "  'Confidence': 90.22195434570312,\n",
       "  'Instances': [],\n",
       "  'Parents': [{'Name': 'Person'}, {'Name': 'Photography'}, {'Name': 'Face'}]}]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_labels(bucket=BUCKET, key=KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human - 99.82290649414062%\n",
      "Person - 99.82290649414062%\n",
      "Face - 99.82290649414062%\n",
      "People - 97.90164947509766%\n",
      "Female - 93.74052429199219%\n",
      "Family - 93.50811767578125%\n",
      "Portrait - 90.22195434570312%\n",
      "Photo - 90.22195434570312%\n",
      "Photography - 90.22195434570312%\n"
     ]
    }
   ],
   "source": [
    "for label in detect_labels(BUCKET, KEY):\n",
    "    print(\"{Name} - {Confidence}%\".format(**label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face (99.99998474121094%)\n",
      "DISGUSTED : 0.06754705309867859%\n",
      "CALM : 0.06720474362373352%\n",
      "CONFUSED : 0.05267829820513725%\n",
      "SAD : 0.03523656725883484%\n",
      "SURPRISED : 0.7813225388526917%\n",
      "FEAR : 0.07914577424526215%\n",
      "ANGRY : 0.10552412271499634%\n",
      "HAPPY : 98.81134796142578%\n",
      "Brightness : 60.807430267333984\n",
      "Sharpness : 89.85481262207031\n",
      "Face (99.99998474121094%)\n",
      "ANGRY : 0.06299644708633423%\n",
      "FEAR : 0.048737939447164536%\n",
      "SURPRISED : 0.07233161479234695%\n",
      "SAD : 0.013773813843727112%\n",
      "CONFUSED : 0.022504432126879692%\n",
      "HAPPY : 99.7130355834961%\n",
      "CALM : 0.009335173293948174%\n",
      "DISGUSTED : 0.057298142462968826%\n",
      "Brightness : 52.563446044921875\n",
      "Sharpness : 83.14741516113281\n",
      "Face (99.99998474121094%)\n",
      "SAD : 0.11543917655944824%\n",
      "CALM : 0.08254587650299072%\n",
      "SURPRISED : 0.5263890624046326%\n",
      "DISGUSTED : 0.2801007032394409%\n",
      "HAPPY : 98.45931243896484%\n",
      "CONFUSED : 0.28651267290115356%\n",
      "ANGRY : 0.1300651580095291%\n",
      "FEAR : 0.1196407675743103%\n",
      "Brightness : 61.75695037841797\n",
      "Sharpness : 86.86019134521484\n",
      "Face (99.9999771118164%)\n",
      "DISGUSTED : 0.08450090885162354%\n",
      "SAD : 0.017469532787799835%\n",
      "HAPPY : 99.72321319580078%\n",
      "ANGRY : 0.030654342845082283%\n",
      "FEAR : 0.02291024476289749%\n",
      "SURPRISED : 0.025447586551308632%\n",
      "CALM : 0.010755443014204502%\n",
      "CONFUSED : 0.08505197614431381%\n",
      "Brightness : 69.53584289550781\n",
      "Sharpness : 89.85481262207031\n",
      "Face (99.99998474121094%)\n",
      "HAPPY : 99.76757049560547%\n",
      "DISGUSTED : 0.03309658169746399%\n",
      "CALM : 0.023390918970108032%\n",
      "ANGRY : 0.032378774136304855%\n",
      "CONFUSED : 0.04383869469165802%\n",
      "SAD : 0.028836451470851898%\n",
      "FEAR : 0.01755603402853012%\n",
      "SURPRISED : 0.05333152413368225%\n",
      "Brightness : 63.12357711791992\n",
      "Sharpness : 89.85481262207031\n"
     ]
    }
   ],
   "source": [
    "FEATURES_BLACKLIST = (\"Landmarks\", \"Emotions\", \"Pose\", \"Quality\", \"BoundingBox\", \"Confidence\")\n",
    "\n",
    "def detect_faces(bucket, key):\n",
    "    \n",
    "    rekognition = boto3.client('rekognition')\n",
    "    \n",
    "    response = rekognition.detect_faces(\n",
    "        Image={\n",
    "            'S3Object': {\n",
    "                'Bucket': bucket,\n",
    "                'Name': key,\n",
    "            }\n",
    "        }, \n",
    "        Attributes=['ALL']\n",
    "    )\n",
    "\n",
    "    return response[\"FaceDetails\"]\n",
    "\n",
    "for face in detect_faces(BUCKET, KEY):\n",
    "    print(\"Face ({Confidence}%)\".format(**face))\n",
    "    \n",
    "    # emotions\n",
    "    for emotion in face['Emotions']:\n",
    "        print(\"{Type} : {Confidence}%\".format(**emotion))\n",
    "    # quality\n",
    "    for quality, value in face['Quality'].items():\n",
    "        print(\"{quality} : {value}\".format(quality=quality, value=value))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Faces (with bounding box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import io\n",
    "from PIL import Image, ImageDraw, ExifTags, ImageColor\n",
    "\n",
    "def show_faces(photo,bucket):\n",
    "     \n",
    "\n",
    "    client=boto3.client('rekognition')\n",
    "\n",
    "    # Load image from S3 bucket\n",
    "    s3_connection = boto3.resource('s3')\n",
    "    s3_object = s3_connection.Object(bucket,photo)\n",
    "    s3_response = s3_object.get()\n",
    "\n",
    "    stream = io.BytesIO(s3_response['Body'].read())\n",
    "    image=Image.open(stream)\n",
    "    \n",
    "    #Call DetectFaces \n",
    "    response = client.detect_faces(Image={'S3Object': {'Bucket': bucket, 'Name': photo}},\n",
    "        Attributes=['ALL'])\n",
    "\n",
    "    imgWidth, imgHeight = image.size  \n",
    "    draw = ImageDraw.Draw(image)  \n",
    "                    \n",
    "\n",
    "    # calculate and display bounding boxes for each detected face       \n",
    "    print('Detected faces for ' + photo)    \n",
    "    for faceDetail in response['FaceDetails']:\n",
    "        print('The detected face is between ' + str(faceDetail['AgeRange']['Low']) \n",
    "              + ' and ' + str(faceDetail['AgeRange']['High']) + ' years old')\n",
    "        \n",
    "        box = faceDetail['BoundingBox']\n",
    "        left = imgWidth * box['Left']\n",
    "        top = imgHeight * box['Top']\n",
    "        width = imgWidth * box['Width']\n",
    "        height = imgHeight * box['Height']\n",
    "                \n",
    "\n",
    "        print('Left: ' + '{0:.0f}'.format(left))\n",
    "        print('Top: ' + '{0:.0f}'.format(top))\n",
    "        print('Face Width: ' + \"{0:.0f}\".format(width))\n",
    "        print('Face Height: ' + \"{0:.0f}\".format(height))\n",
    "\n",
    "        points = (\n",
    "            (left,top),\n",
    "            (left + width, top),\n",
    "            (left + width, top + height),\n",
    "            (left , top + height),\n",
    "            (left, top)\n",
    "\n",
    "        )\n",
    "        draw.line(points, fill='#00d400', width=2)\n",
    "\n",
    "        # Alternatively can draw rectangle. However you can't set line width.\n",
    "        #draw.rectangle([left,top, left + width, top + height], outline='#00d400') \n",
    "\n",
    "    image.show()\n",
    "\n",
    "    return len(response['FaceDetails'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected faces for photo3.jpeg\n",
      "The detected face is between 22 and 34 years old\n",
      "Left: 189\n",
      "Top: 90\n",
      "Face Width: 125\n",
      "Face Height: 183\n",
      "The detected face is between 21 and 33 years old\n",
      "Left: 65\n",
      "Top: 97\n",
      "Face Width: 125\n",
      "Face Height: 177\n",
      "The detected face is between 22 and 34 years old\n",
      "Left: 564\n",
      "Top: 114\n",
      "Face Width: 122\n",
      "Face Height: 171\n",
      "The detected face is between 30 and 46 years old\n",
      "Left: 325\n",
      "Top: 62\n",
      "Face Width: 111\n",
      "Face Height: 181\n",
      "The detected face is between 22 and 34 years old\n",
      "Left: 448\n",
      "Top: 101\n",
      "Face Width: 109\n",
      "Face Height: 173\n",
      "faces detected: 5\n"
     ]
    }
   ],
   "source": [
    "faces_count=show_faces(KEY,BUCKET)\n",
    "print(\"faces detected: \" + str(faces_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "def translate_my_text(text, sourceLang, targetLang):\n",
    "    translate = boto3.client(service_name='translate',use_ssl=True)\n",
    "\n",
    "    result = translate.translate_text(Text=text, \n",
    "                SourceLanguageCode=sourceLang, TargetLanguageCode=targetLang)\n",
    "    print('TranslatedText: ' + result.get('TranslatedText'))\n",
    "    print('SourceLanguageCode: ' + result.get('SourceLanguageCode'))\n",
    "    print('TargetLanguageCode: ' + result.get('TargetLanguageCode'))\n",
    "\n",
    "lang_lookup = {'Arabic': 'ar',\n",
    " 'Chinese-Simplified': 'zh',\n",
    " 'Chinese-Traditional': 'zh-TW',\n",
    " 'Czech': 'cs',\n",
    " 'Danish': 'da',\n",
    " 'Dutch': 'nl',\n",
    " 'English': 'en',\n",
    " 'Finnish': 'fi',\n",
    " 'French': 'fr',\n",
    " 'German': 'de',\n",
    " 'Hebrew': 'he',\n",
    " 'Indonesian': 'id',\n",
    " 'Italian': 'it',\n",
    " 'Japanese': 'ja',\n",
    " 'Korean': 'ko',\n",
    " 'Polish': 'pl',\n",
    " 'Portuguese': 'pt',\n",
    " 'Russian': 'ru',\n",
    " 'Spanish': 'es',\n",
    " 'Swedish': 'sv',\n",
    " 'Turkish': 'tr',\n",
    " 'Hindi': 'hi'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TranslatedText: हाय, मेरा नाम सुमन है, आप सभी के लिए धन्यवाद\n",
      "SourceLanguageCode: en\n",
      "TargetLanguageCode: hi\n"
     ]
    }
   ],
   "source": [
    "text = \"Hi, My name is Suman, thank you to all of you\"\n",
    "sourceL = \"English\"\n",
    "targetL = \"Hindi\"\n",
    "\n",
    "targetLang = lang_lookup[targetL]\n",
    "sourceLang = lang_lookup[sourceL]\n",
    "\n",
    "translate_my_text(text=text, sourceLang=sourceLang, targetLang=targetLang)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Comprehend "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "from pprint import pprint as pp\n",
    "\n",
    "def get_sentiment(data):\n",
    "    \n",
    "    comprehend = boto3.client(service_name='comprehend')\n",
    "\n",
    "    print('Calling DetectSentiment')\n",
    "    raw_data = json.dumps(comprehend.detect_sentiment(Text=data, LanguageCode='en'), sort_keys=True, indent=4)\n",
    "    raw_data = json.loads(raw_data)\n",
    "    sentiment = raw_data[\"Sentiment\"]\n",
    "    sentimentScore = raw_data[\"SentimentScore\"]\n",
    "    \n",
    "    print(f\"Sentiment is : {sentiment}\")\n",
    "    print(\"Sentiment score is :\")\n",
    "    pp(sentimentScore)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling DetectSentiment\n",
      "Sentiment is : POSITIVE\n",
      "Sentiment score is :\n",
      "{'Mixed': 7.307636451514554e-07,\n",
      " 'Negative': 6.124450010247529e-05,\n",
      " 'Neutral': 0.001250004512257874,\n",
      " 'Positive': 0.9986880421638489}\n"
     ]
    }
   ],
   "source": [
    "text = \"Thanks for joinig in, its a pleasure to meet you all amazing people\"\n",
    "get_sentiment(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling DetectEntities\n",
      "{\n",
      "    \"Entities\": [\n",
      "        {\n",
      "            \"BeginOffset\": 25,\n",
      "            \"EndOffset\": 29,\n",
      "            \"Score\": 0.9998410940170288,\n",
      "            \"Text\": \"Pune\",\n",
      "            \"Type\": \"LOCATION\"\n",
      "        },\n",
      "        {\n",
      "            \"BeginOffset\": 30,\n",
      "            \"EndOffset\": 35,\n",
      "            \"Score\": 0.9996994733810425,\n",
      "            \"Text\": \"today\",\n",
      "            \"Type\": \"DATE\"\n",
      "        },\n",
      "        {\n",
      "            \"BeginOffset\": 44,\n",
      "            \"EndOffset\": 50,\n",
      "            \"Score\": 0.9843429327011108,\n",
      "            \"Text\": \"Amazon\",\n",
      "            \"Type\": \"ORGANIZATION\"\n",
      "        }\n",
      "    ],\n",
      "    \"ResponseMetadata\": {\n",
      "        \"HTTPHeaders\": {\n",
      "            \"content-length\": \"296\",\n",
      "            \"content-type\": \"application/x-amz-json-1.1\",\n",
      "            \"date\": \"Wed, 25 Mar 2020 12:48:38 GMT\",\n",
      "            \"x-amzn-requestid\": \"354bf7e4-4b36-4910-9627-7189eafdae3e\"\n",
      "        },\n",
      "        \"HTTPStatusCode\": 200,\n",
      "        \"RequestId\": \"354bf7e4-4b36-4910-9627-7189eafdae3e\",\n",
      "        \"RetryAttempts\": 0\n",
      "    }\n",
      "}\n",
      "End of DetectEntities\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comprehend = boto3.client(service_name='comprehend')\n",
    "text = 'It was get to be here in Pune today, I love Amazon and more that that I love you all'\n",
    "\n",
    "print('Calling DetectEntities')\n",
    "print(json.dumps(comprehend.detect_entities(Text=text, LanguageCode='en'),\n",
    "                 sort_keys=True, indent=4))\n",
    "print('End of DetectEntities\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
